{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArseniyKoz/uni.neuralnetworks/blob/main/nn_mnist_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVlg_ffSvnY4",
        "outputId": "85716aab-b1dd-48a1-ed76-0b189a267f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 16477877.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 490608.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4493978.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2503683.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 128\n",
        "\n",
        "# convert data to torch.FloatTensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# get the training datasets\n",
        "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
        "\n",
        "# prepare data loader\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
        "print(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "images = images.numpy()\n",
        "\n",
        "img = np.squeeze(images[7])\n",
        "\n",
        "flg = plt.figure(figsize = (3, 3))\n",
        "ax = flg.add_subplot(111)\n",
        "ax.imshow(img, cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "HPVuPpFCwVst",
        "outputId": "456ecf1b-2a85-4a64-e3b5-625f1c170a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc7a4ad2ce0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, input_size, hidden_dim, dropout, output_size):\n",
        "    super(Discriminator, self).__init__()\n",
        "    # TO DO: define all layers\n",
        "    # define hidden linear layers (2-3)\n",
        "    self.hidden1 = nn.Linear(input_size, 8*hidden_dim)\n",
        "    self.hidden2 = nn.Linear(8*hidden_dim, 4*hidden_dim)\n",
        "    self.hidden3 = nn.Linear(4*hidden_dim, 2*hidden_dim)\n",
        "    self.hidden4 = nn.Linear(2*hidden_dim, hidden_dim)\n",
        "\n",
        "    # final fully-connected layer\n",
        "    self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    # dropout layer\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.lRelu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    self.sigm = nn.Sigmoid()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    #TO DO: make forward\n",
        "    # flatten image\n",
        "    out = x.view(-1, 28*28)\n",
        "    #out = self.flatten(x)\n",
        "\n",
        "    # pass x through all layers\n",
        "    # apply leaky relu activation to all hidden layers\n",
        "    out = self.hidden1(out)\n",
        "    out = self.lRelu(out)\n",
        "    out = self.dropout(out)\n",
        "\n",
        "    out = self.hidden2(out)\n",
        "    out = self.lRelu(out)\n",
        "    out = self.dropout(out)\n",
        "\n",
        "    out = self.hidden3(out)\n",
        "    out = self.lRelu(out)\n",
        "    out = self.dropout(out)\n",
        "\n",
        "    out = self.hidden4(out)\n",
        "    out = self.lRelu(out)\n",
        "    out = self.dropout(out)\n",
        "    # dropout\n",
        "\n",
        "    # final output\n",
        "    out = self.fc(out)\n",
        "    #out = self.sigm(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "4CumEI0ywe6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_size, hidden_dim, dropout, output_size):\n",
        "    super(Generator, self).__init__()\n",
        "    # TODO: define all layers\n",
        "    # define hidden linear layers (2-3)\n",
        "    self.hidden1 = nn.Linear(input_size, hidden_dim)\n",
        "    self.hidden2 = nn.Linear(hidden_dim, 2*hidden_dim)\n",
        "    self.hidden3 = nn.Linear(2*hidden_dim, 4*hidden_dim)\n",
        "    self.hidden4 = nn.Linear(4*hidden_dim, 8*hidden_dim)\n",
        "\n",
        "    # final fully-connected layer\n",
        "    self.fc = nn.Linear(8*hidden_dim, output_size)\n",
        "\n",
        "    # dropout layer\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.lRelu = nn.LeakyReLU(0.2)\n",
        "    self.tan = nn.Tanh()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # pass x through all layers\n",
        "    out = self.hidden1(x)\n",
        "    out = self.lRelu(out)\n",
        "    out = self.dropout(out)\n",
        "\n",
        "    out = self.hidden2(out)\n",
        "    out = self.lRelu(out)\n",
        "    out = self.dropout(out)\n",
        "\n",
        "    out = self.hidden3(out)\n",
        "    out = self.lRelu(out)\n",
        "    out = self.dropout(out)\n",
        "\n",
        "    out = self.hidden4(out)\n",
        "    out = self.lRelu(out)\n",
        "    out = self.dropout(out)\n",
        "\n",
        "    out = self.fc(out)\n",
        "    out = self.tan(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "C4Y9gNy8wd-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator hyperparams\n",
        "k = 28\n",
        "# Size of input image to discriminator (28*28)\n",
        "input_size = k*k\n",
        "\n",
        "# Size of discriminator output (real or fake)\n",
        "d_output_size = 1\n",
        "\n",
        "# Size of *last* hidden layer in the discriminator\n",
        "d_hidden_size = 64\n",
        "\n",
        "# Generator hyperparams\n",
        "# Size of latent vector to give to generator\n",
        "z_size = 100\n",
        "\n",
        "# Size of discriminator output (generated image)\n",
        "g_output_size = k*k\n",
        "\n",
        "# Size of *first* hidden layer in the generator\n",
        "g_hidden_size = 64\n",
        "\n",
        "dropout = 0.3\n",
        "lr = 0.0005"
      ],
      "metadata": {
        "id": "DXictcLswVpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = Discriminator(input_size, d_hidden_size, dropout, d_output_size)\n",
        "G = Generator(z_size, g_hidden_size, dropout, g_output_size)\n",
        "print(D)\n",
        "print()\n",
        "G"
      ],
      "metadata": {
        "id": "HcfYGpyA8PqP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13caed46-c759-4430-c621-ba18dd71f390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator(\n",
            "  (hidden1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (hidden2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (hidden3): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (hidden4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (lRelu): LeakyReLU(negative_slope=0.2)\n",
            "  (sigm): Sigmoid()\n",
            ")\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (hidden1): Linear(in_features=100, out_features=64, bias=True)\n",
              "  (hidden2): Linear(in_features=64, out_features=128, bias=True)\n",
              "  (hidden3): Linear(in_features=128, out_features=256, bias=True)\n",
              "  (hidden4): Linear(in_features=256, out_features=512, bias=True)\n",
              "  (fc): Linear(in_features=512, out_features=784, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (lRelu): LeakyReLU(negative_slope=0.2)\n",
              "  (tan): Tanh()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate losses\n",
        "def real_loss(D_out, smooth=False):\n",
        "    # compare logits to real labels\n",
        "    # smooth labels if smooth=True\n",
        "    batch_size = D_out.size(0)\n",
        "    if smooth:\n",
        "        labels = torch.ones(batch_size)*0.9\n",
        "    else:\n",
        "        labels = torch.ones(batch_size)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "    loss = criterion(D_out.squeeze(),labels)\n",
        "    return loss\n",
        "\n",
        "def fake_loss(D_out):\n",
        "    # compare logits to fake labels\n",
        "    batch_size = D_out.size(0)\n",
        "    labels = torch.zeros(batch_size)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    loss = criterion(D_out.squeeze(),labels)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "TwSpAj5e8kup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "# Create optimizers for the discriminator and generator\n",
        "d_optimizer = optim.Adam(D.parameters(),lr)\n",
        "g_optimizer = optim.Adam(G.parameters(),lr)"
      ],
      "metadata": {
        "id": "lZqA3gLWSAPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "\n",
        "# training hyperparams\n",
        "num_epochs = 200\n",
        "\n",
        "# keep track of loss and generated, \"fake\" samples\n",
        "samples = []\n",
        "losses = []\n",
        "\n",
        "print_every = 400\n",
        "\n",
        "# Get some fixed data for sampling. These are images that are held\n",
        "# constant throughout training, and allow us to inspect the model's performance\n",
        "sample_size=16\n",
        "fixed_z = np.random.uniform(-1,1,size = (batch_size, z_size))\n",
        "fixed_z = torch.from_numpy(fixed_z).float()\n",
        "\n",
        "# train the network\n",
        "D.train()\n",
        "G.train()\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    for batch_i, (real_images, _) in enumerate(train_loader):\n",
        "\n",
        "        batch_size = real_images.size(0)\n",
        "\n",
        "        ## Important rescaling step ##\n",
        "        real_images = real_images*2 - 1  # rescale input images from [0,1) to [-1, 1)\n",
        "\n",
        "        # ============================================\n",
        "        #            TRAIN THE DISCRIMINATOR\n",
        "        # ============================================\n",
        "\n",
        "        # 1. Train with real images\n",
        "        d_optimizer.zero_grad()\n",
        "\n",
        "        # Compute the discriminator losses on real images\n",
        "        # use smoothed labels\n",
        "        op_real = D(real_images)\n",
        "        d_real_loss = real_loss(op_real,smooth = True)\n",
        "\n",
        "\n",
        "        # 2. Train with fake images\n",
        "\n",
        "        # Generate fake images\n",
        "        z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
        "        z = torch.from_numpy(z).float()\n",
        "        fake_images = G(z)\n",
        "\n",
        "        # Compute the discriminator losses on fake images\n",
        "        op_fake = D(fake_images)\n",
        "        #print(type(fake_loss))\n",
        "        d_fake_loss = fake_loss(op_fake)\n",
        "\n",
        "        # add up real and fake losses and perform backprop\n",
        "        d_loss = d_fake_loss + d_real_loss\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # =========================================\n",
        "        #            TRAIN THE GENERATOR\n",
        "        # =========================================\n",
        "\n",
        "        # 1. Train with fake images and flipped labels\n",
        "        g_optimizer.zero_grad()\n",
        "\n",
        "        # Generate fake images\n",
        "        z = np.random.uniform(-1,1,size = (batch_size, z_size))\n",
        "        z = torch.from_numpy(z).float()\n",
        "        fake_images = G(z)\n",
        "\n",
        "        # Compute the discriminator losses on fake images\n",
        "        # using flipped labels!\n",
        "        d_fake_loss = D(fake_images)\n",
        "        g_loss = real_loss(d_fake_loss)\n",
        "        # perform backprop\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "\n",
        "        # Print some loss stats\n",
        "        if batch_i % print_every == 0:\n",
        "            # print discriminator and generator loss\n",
        "            print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
        "                    epoch+1, num_epochs, d_loss.item(), g_loss.item()))\n",
        "\n",
        "\n",
        "    ## AFTER EACH EPOCH##\n",
        "    # append discriminator loss and generator loss\n",
        "    losses.append((d_loss.item(), g_loss.item()))\n",
        "\n",
        "    # generate and save sample, fake images\n",
        "    G.eval() # eval mode for generating samples\n",
        "    samples_z = G(fixed_z)\n",
        "    samples.append(samples_z)\n",
        "    G.train() # back to train mode\n",
        "\n",
        "\n",
        "# Save training generator samples\n",
        "with open('train_samples.pkl', 'wb') as f:\n",
        "    pkl.dump(samples, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33SzDyLmSYqm",
        "outputId": "34f65e28-b3d1-4f97-f7bb-4ada55049432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [    1/  200] | d_loss: 1.3965 | g_loss: 0.6499\n",
            "Epoch [    1/  200] | d_loss: 0.7801 | g_loss: 5.4298\n",
            "Epoch [    2/  200] | d_loss: 0.7211 | g_loss: 3.9959\n",
            "Epoch [    2/  200] | d_loss: 1.2193 | g_loss: 1.1926\n",
            "Epoch [    3/  200] | d_loss: 0.7386 | g_loss: 3.7825\n",
            "Epoch [    3/  200] | d_loss: 1.3813 | g_loss: 0.6387\n",
            "Epoch [    4/  200] | d_loss: 1.3624 | g_loss: 0.6914\n",
            "Epoch [    4/  200] | d_loss: 1.2790 | g_loss: 0.9914\n",
            "Epoch [    5/  200] | d_loss: 1.5182 | g_loss: 0.5902\n",
            "Epoch [    5/  200] | d_loss: 1.2381 | g_loss: 0.9176\n",
            "Epoch [    6/  200] | d_loss: 1.4632 | g_loss: 0.9585\n",
            "Epoch [    6/  200] | d_loss: 0.8651 | g_loss: 2.6227\n",
            "Epoch [    7/  200] | d_loss: 0.9536 | g_loss: 3.4520\n",
            "Epoch [    7/  200] | d_loss: 0.8329 | g_loss: 3.2210\n",
            "Epoch [    8/  200] | d_loss: 0.8355 | g_loss: 3.5184\n",
            "Epoch [    8/  200] | d_loss: 0.8798 | g_loss: 3.1180\n",
            "Epoch [    9/  200] | d_loss: 0.6027 | g_loss: 2.5558\n",
            "Epoch [    9/  200] | d_loss: 0.7294 | g_loss: 3.6135\n",
            "Epoch [   10/  200] | d_loss: 0.9750 | g_loss: 2.5578\n",
            "Epoch [   10/  200] | d_loss: 0.7207 | g_loss: 2.3714\n",
            "Epoch [   11/  200] | d_loss: 0.8313 | g_loss: 2.7341\n",
            "Epoch [   11/  200] | d_loss: 1.3438 | g_loss: 1.0689\n",
            "Epoch [   12/  200] | d_loss: 0.8489 | g_loss: 2.4284\n",
            "Epoch [   12/  200] | d_loss: 1.0407 | g_loss: 2.2762\n",
            "Epoch [   13/  200] | d_loss: 0.7537 | g_loss: 2.5148\n",
            "Epoch [   13/  200] | d_loss: 0.7873 | g_loss: 2.7415\n",
            "Epoch [   14/  200] | d_loss: 0.9905 | g_loss: 2.4266\n",
            "Epoch [   14/  200] | d_loss: 0.8032 | g_loss: 2.3139\n",
            "Epoch [   15/  200] | d_loss: 0.8035 | g_loss: 2.5886\n",
            "Epoch [   15/  200] | d_loss: 0.8332 | g_loss: 2.1184\n",
            "Epoch [   16/  200] | d_loss: 0.9825 | g_loss: 1.9574\n",
            "Epoch [   16/  200] | d_loss: 1.0589 | g_loss: 1.6006\n",
            "Epoch [   17/  200] | d_loss: 0.9619 | g_loss: 2.6063\n",
            "Epoch [   17/  200] | d_loss: 0.8476 | g_loss: 1.7718\n",
            "Epoch [   18/  200] | d_loss: 0.8983 | g_loss: 2.6229\n",
            "Epoch [   18/  200] | d_loss: 0.8839 | g_loss: 2.3569\n",
            "Epoch [   19/  200] | d_loss: 0.9618 | g_loss: 2.3613\n",
            "Epoch [   19/  200] | d_loss: 0.8856 | g_loss: 2.2653\n",
            "Epoch [   20/  200] | d_loss: 0.9152 | g_loss: 2.9335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "losses = np.array(losses)\n",
        "plt.plot(losses.T[0], label='Discriminator')\n",
        "plt.plot(losses.T[1], label='Generator')\n",
        "plt.title(\"Training Losses\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "W60t6HiNSee4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function for viewing a list of passed in sample images\n",
        "def view_samples(epoch, samples):\n",
        "    fig, axes = plt.subplots(figsize=(7,7), nrows=10, ncols=10, sharey=True, sharex=True)\n",
        "    for ax, img in zip(axes.flatten(), samples[epoch]):\n",
        "        img = img.detach()\n",
        "        ax.xaxis.set_visible(False)\n",
        "        ax.yaxis.set_visible(False)\n",
        "        im = ax.imshow(img.reshape((28,28)), cmap='Greys_r')"
      ],
      "metadata": {
        "id": "LXoMoDNkShoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train_samples.pkl', 'rb') as f:\n",
        "  samples = pkl.load(f)"
      ],
      "metadata": {
        "id": "5TiDL5ArSlXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "view_samples(-1, samples)"
      ],
      "metadata": {
        "id": "Zj7_MHtkSoYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = 25 # split epochs into 10, so 100/10 = every 10 epochs\n",
        "cols = 6\n",
        "fig, axes = plt.subplots(figsize=(7,12), nrows=rows, ncols=cols, sharex=True, sharey=True)\n",
        "\n",
        "for sample, ax_row in zip(samples[::int(len(samples)/rows)], axes):\n",
        "    for img, ax in zip(sample[::int(len(sample)/cols)], ax_row):\n",
        "        img = img.detach()\n",
        "        ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
        "        ax.xaxis.set_visible(False)\n",
        "        ax.yaxis.set_visible(False)"
      ],
      "metadata": {
        "id": "mOp7gmkxSrSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly generated, new latent vectors\n",
        "sample_size=100\n",
        "rand_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
        "rand_z = torch.from_numpy(rand_z).float()\n",
        "\n",
        "G.eval() # eval mode\n",
        "# generated samples\n",
        "rand_images = G(rand_z)\n",
        "\n",
        "# 0 indicates the first set of samples in the passed in list\n",
        "# and we only have one batch of samples, here\n",
        "view_samples(0, [rand_images])"
      ],
      "metadata": {
        "id": "soDdCamNSvBn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}